# configs/cifar100.yaml

project_name: "boost-self-supervised-dataset-distillation"
experiment_name: "cifar100_distillation"

data:
  name: "CIFAR100"
  path: "./data"
  resolution: [3, 32, 32]
  num_classes: 100
  full_dataset_size: 50000

distillation:
  storage_budget_N: 100
  num_distilled_images_m: 100
  steps: 30000
  optimizer:
    name: "AdamW"
    lr: 0.001
    decay_type: "linear"

parametrization:
  image_bases_U: 200
  repr_bases_V: 200
  image_basis_size: 16
  upsampling_scale: 2

models:
  teacher:
    arch: "ResNet18"
    path: "./teacher_models/resnet18_barlow_twins_cifar100.pth"
    feature_dim: 512
  inner_cnn:
    channels: [128, 256, 512]
    feature_dim: 512
  approximation_mlp:
    hidden_dim: 4

augmentations:
  rotate: [90, 180, 270]

saving:
  distilled_assets_dir: "./distilled_assets/cifar100_N100"

model_pool:
  size_L: 10
  inner_loop_steps_Z: 1000

evaluation:
  epochs: 1000
  lr: 0.1
  weight_decay: 1e-4
  # Linear evaluation settings
  linear_epochs: 100
  linear_lr: 0.2